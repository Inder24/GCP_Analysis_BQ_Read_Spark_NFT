{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a73e0748", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"}, {"name": "stderr", "output_type": "stream", "text": "Ivy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\ncom.google.cloud.spark#spark-bigquery-with-dependencies_2.12 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-d29e9d3f-b4a3-4117-a703-9d6d1cb8b5ad;1.0\n\tconfs: [default]\n\tfound com.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.23.2 in central\n:: resolution report :: resolve 337ms :: artifacts dl 21ms\n\t:: modules in use:\n\tcom.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.23.2 from central in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n\t---------------------------------------------------------------------\n:: retrieving :: org.apache.spark#spark-submit-parent-d29e9d3f-b4a3-4117-a703-9d6d1cb8b5ad\n\tconfs: [default]\n\t0 artifacts copied, 1 already retrieved (0kB/6ms)\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/04/13 07:28:45 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n22/04/13 07:28:45 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n22/04/13 07:28:45 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n22/04/13 07:28:45 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nspark2 =SparkSession.builder \\\n  .master('local[*]') \\\n  .appName('conversions') \\\n  .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.23.2') \\\n  .config('spark.executor.memory', '4G') \\\n  .config('spark.driver.memory', '45G') \\\n  .config('spark.driver.maxResultSize', '10G') \\\n  .config(\"spark.memory.offHeap.size\",\"16g\") \\\n  .getOrCreate() \n#   .config(\"spark.executor.memory\", \"70g\")\n#   .config(\"spark.memory.offHeap.size\",\"8g\")  \\\n#   .config(\"spark.driver.memory\", \"8g\") \\\nsqlContext = SQLContext(spark2)"}, {"cell_type": "code", "execution_count": 2, "id": "69fa95b4", "metadata": {}, "outputs": [{"data": {"text/plain": "'10G'"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": " spark2.conf.get('spark.driver.maxResultSize')"}, {"cell_type": "code", "execution_count": 3, "id": "328bb24c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Copying gs://nft_sql_lite_db/nfts.sqlite...\n\\ [1 files][  6.9 GiB/  6.9 GiB]   49.3 MiB/s                                   \nOperation completed over 1 objects/6.9 GiB.                                      \n"}], "source": "!gsutil cp gs://nft_sql_lite_db/nfts.sqlite /tmp/nfts.sqlite"}, {"cell_type": "code", "execution_count": 4, "id": "7d1ec776", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "/tmp/nfts.sqlite\r\n"}], "source": "!ls /tmp/nfts.sqlite"}, {"cell_type": "code", "execution_count": 5, "id": "9e04ca98", "metadata": {}, "outputs": [], "source": "import sqlite3\nimport csv\nimport pandas as pd\n\ndb_path = '/tmp/nfts.sqlite'"}, {"cell_type": "code", "execution_count": 9, "id": "a5f55855", "metadata": {}, "outputs": [], "source": "query = 'SELECT * from current_owners'\n\nconn = sqlite3.connect(db_path)\n\na_pandas_df = pd.read_sql_query(query, conn)"}, {"cell_type": "code", "execution_count": 10, "id": "e694d808", "metadata": {}, "outputs": [], "source": "spark_current_owner = sqlContext.createDataFrame(data=a_pandas_df)"}, {"cell_type": "code", "execution_count": 11, "id": "d842af50", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- nft_address: string (nullable = true)\n |-- token_id: string (nullable = true)\n |-- owner: string (nullable = true)\n\n"}], "source": "spark_current_owner.printSchema()"}, {"cell_type": "code", "execution_count": 12, "id": "b42ebb5a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 0:>                                                          (0 + 0) / 1]\r22/04/12 12:40:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 0 contains a task of very large size (173673 KiB). The maximum recommended task size is 1000 KiB.\n\r[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------+--------------------+\n|         nft_address|token_id|               owner|\n+--------------------+--------+--------------------+\n|0x00000000000b7F8...|       0|0xb776cAb26B9e6Be...|\n|0x00000000000b7F8...|       1|0x8A73024B39A4477...|\n|0x00000000000b7F8...|      10|0x5e5C817E9264B46...|\n|0x00000000000b7F8...|      11|0x8376f63c13b99D3...|\n|0x00000000000b7F8...|      12|0xb5e34552F32BA92...|\n+--------------------+--------+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r[Stage 0:===========================================================(1 + 0) / 1]\r\r                                                                                \r"}], "source": "spark_current_owner.show(5)"}, {"cell_type": "code", "execution_count": null, "id": "84565f86", "metadata": {}, "outputs": [], "source": "spark_current_owner.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.nft_current_owners').partitionBy(\"nft_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 2, "id": "93362a4d", "metadata": {"collapsed": true}, "outputs": [{"ename": "DatabaseError", "evalue": "Execution failed on sql 'SELECT * from nfts': no such table: nfts", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/sql.py:1725\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1725\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n", "\u001b[0;31mOperationalError\u001b[0m: no such table: nfts", "\nThe above exception was the direct cause of the following exception:\n", "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)", "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT * from nfts\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(db_path)\n\u001b[0;32m----> 5\u001b[0m pandas_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/sql.py:388\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03mparameter will be converted to UTC.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/sql.py:1771\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1762\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1767\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1768\u001b[0m ):\n\u001b[1;32m   1770\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 1771\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   1774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/sql.py:1737\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1737\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n", "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * from nfts': no such table: nfts"]}], "source": "query = 'SELECT * from nfts'\n\nconn = sqlite3.connect(db_path)\n\npandas_df = pd.read_sql_query(query, conn)"}, {"cell_type": "code", "execution_count": null, "id": "0d4251f3", "metadata": {}, "outputs": [], "source": "spark_nfts = sqlContext.createDataFrame(data=pandas_df)"}, {"cell_type": "code", "execution_count": null, "id": "48b3d4a4", "metadata": {}, "outputs": [], "source": "spark_nfts.printSchema()\nspark_nfts.show(5)"}, {"cell_type": "code", "execution_count": null, "id": "a57d3dc7", "metadata": {}, "outputs": [], "source": "spark_nfts.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.nfts').mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 2, "id": "acc7b6bd", "metadata": {}, "outputs": [], "source": "# query = 'SELECT * from transfers'\n\nconn = sqlite3.connect(db_path)\n\n# pandas_df = pd.read_sql_query(query, conn)"}, {"cell_type": "code", "execution_count": 3, "id": "7d432d71", "metadata": {}, "outputs": [], "source": "cur = conn.execute(\"SELECT * from transfers\")\n\nrows = cur.fetchall()"}, {"cell_type": "code", "execution_count": 7, "id": "d4f47a6b", "metadata": {}, "outputs": [], "source": "table_columns = ['eventId', 'transaction_hash', 'block_number', 'nft_address', 'token_id', 'from_address', 'to_address', 'transaction_value', 'timestamp']\n\nwith open(\"transfers.csv\", \"w\", newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(table_columns)\n    writer.writerows(rows)"}, {"cell_type": "code", "execution_count": 3, "id": "6ba30d82", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eventId</th>\n      <th>transaction_hash</th>\n      <th>block_number</th>\n      <th>nft_address</th>\n      <th>token_id</th>\n      <th>from_address</th>\n      <th>to_address</th>\n      <th>transaction_value</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cd816651-56b2-4ed9-887c-c83de732428d</td>\n      <td>0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...</td>\n      <td>12936373</td>\n      <td>0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205</td>\n      <td>6682934142305278177002530107138320246486863356...</td>\n      <td>0x25f1d709b329C7349b8209851E90eFa3a7f60178</td>\n      <td>0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa</td>\n      <td>0.0</td>\n      <td>1627776481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>82cc5228-eb80-4e0d-9f6f-e644dec3ab06</td>\n      <td>0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...</td>\n      <td>12936373</td>\n      <td>0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205</td>\n      <td>1198507443711741845273832738859307575893198744...</td>\n      <td>0x0737E7162C88E9FBB963334e4Bfe6e97447fF811</td>\n      <td>0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa</td>\n      <td>0.0</td>\n      <td>1627776481</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6e1f9cc4-d1df-4a6b-972d-a20765beb326</td>\n      <td>0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...</td>\n      <td>12936373</td>\n      <td>0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205</td>\n      <td>1541220344281436903042142177888467401468454835...</td>\n      <td>0xA0fEc186c4b3FAd39ca373dFdd52E79C2495F2c3</td>\n      <td>0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa</td>\n      <td>0.0</td>\n      <td>1627776481</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43dc27a7-a72d-4894-809c-e868de05f7ee</td>\n      <td>0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...</td>\n      <td>12936373</td>\n      <td>0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205</td>\n      <td>7993840355029527745913866651030234226423689128...</td>\n      <td>0x90bE22069560A9bAd99543B4A922d1FE34Ae84E9</td>\n      <td>0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa</td>\n      <td>0.0</td>\n      <td>1627776481</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47b7839b-9b87-442d-b2c1-9ebedcad8e06</td>\n      <td>0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...</td>\n      <td>12936373</td>\n      <td>0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205</td>\n      <td>1123719749142984581497870712442861055686734521...</td>\n      <td>0xA8E9C42Ebb915EeEC5080B7Bcc5D844475595091</td>\n      <td>0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa</td>\n      <td>0.0</td>\n      <td>1627776481</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                eventId  \\\n0  cd816651-56b2-4ed9-887c-c83de732428d   \n1  82cc5228-eb80-4e0d-9f6f-e644dec3ab06   \n2  6e1f9cc4-d1df-4a6b-972d-a20765beb326   \n3  43dc27a7-a72d-4894-809c-e868de05f7ee   \n4  47b7839b-9b87-442d-b2c1-9ebedcad8e06   \n\n                                    transaction_hash  block_number  \\\n0  0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...      12936373   \n1  0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...      12936373   \n2  0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...      12936373   \n3  0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...      12936373   \n4  0x0c73daad5e6946e6b2f1374846d6ba3025d6e6a2569f...      12936373   \n\n                                  nft_address  \\\n0  0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205   \n1  0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205   \n2  0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205   \n3  0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205   \n4  0x629A673A8242c2AC4B7B8C5D8735fbeac21A6205   \n\n                                            token_id  \\\n0  6682934142305278177002530107138320246486863356...   \n1  1198507443711741845273832738859307575893198744...   \n2  1541220344281436903042142177888467401468454835...   \n3  7993840355029527745913866651030234226423689128...   \n4  1123719749142984581497870712442861055686734521...   \n\n                                 from_address  \\\n0  0x25f1d709b329C7349b8209851E90eFa3a7f60178   \n1  0x0737E7162C88E9FBB963334e4Bfe6e97447fF811   \n2  0xA0fEc186c4b3FAd39ca373dFdd52E79C2495F2c3   \n3  0x90bE22069560A9bAd99543B4A922d1FE34Ae84E9   \n4  0xA8E9C42Ebb915EeEC5080B7Bcc5D844475595091   \n\n                                   to_address  transaction_value   timestamp  \n0  0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa                0.0  1627776481  \n1  0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa                0.0  1627776481  \n2  0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa                0.0  1627776481  \n3  0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa                0.0  1627776481  \n4  0xC69b4c6fFDBaF843A0d0588c99E3C67f27069BEa                0.0  1627776481  "}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "transfer_data = pd.read_csv('transfers.csv')\n\ntransfer_data.head()"}, {"cell_type": "code", "execution_count": null, "id": "9d97753f", "metadata": {}, "outputs": [], "source": "spark_transfer = sqlContext.createDataFrame(data=transfer_data)"}, {"cell_type": "code", "execution_count": 6, "id": "f550555d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- eventId: string (nullable = true)\n |-- transaction_hash: string (nullable = true)\n |-- block_number: long (nullable = true)\n |-- nft_address: string (nullable = true)\n |-- token_id: string (nullable = true)\n |-- from_address: string (nullable = true)\n |-- to_address: string (nullable = true)\n |-- transaction_value: double (nullable = true)\n |-- timestamp: long (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "22/04/12 13:59:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 0 contains a task of very large size (222171 KiB). The maximum recommended task size is 1000 KiB.\n\r[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|             eventId|    transaction_hash|block_number|         nft_address|            token_id|        from_address|          to_address|transaction_value| timestamp|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|cd816651-56b2-4ed...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|66829341423052781...|0x25f1d709b329C73...|0xC69b4c6fFDBaF84...|              0.0|1627776481|\n|82cc5228-eb80-4e0...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|11985074437117418...|0x0737E7162C88E9F...|0xC69b4c6fFDBaF84...|              0.0|1627776481|\n|6e1f9cc4-d1df-4a6...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|15412203442814369...|0xA0fEc186c4b3FAd...|0xC69b4c6fFDBaF84...|              0.0|1627776481|\n|43dc27a7-a72d-489...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|79938403550295277...|0x90bE22069560A9b...|0xC69b4c6fFDBaF84...|              0.0|1627776481|\n|47b7839b-9b87-442...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|11237197491429845...|0xA8E9C42Ebb915Ee...|0xC69b4c6fFDBaF84...|              0.0|1627776481|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "spark_transfer.printSchema()\nspark_transfer.show(5)"}, {"cell_type": "code", "execution_count": 2, "id": "cd5f21c0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|             eventId|    transaction_hash|block_number|         nft_address|            token_id|        from_address|          to_address|transaction_value| timestamp|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|cd816651-56b2-4ed...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|66829341423052781...|0x25f1d709b329C73...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|82cc5228-eb80-4e0...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|11985074437117418...|0x0737E7162C88E9F...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|6e1f9cc4-d1df-4a6...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|15412203442814369...|0xA0fEc186c4b3FAd...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|43dc27a7-a72d-489...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|79938403550295277...|0x90bE22069560A9b...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|47b7839b-9b87-442...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|11237197491429845...|0xA8E9C42Ebb915Ee...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|aa9cfbfe-e787-4e1...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|10075266537522611...|0xDaf6ae49094Fde8...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|2c6e69bc-29aa-4f4...|0x0c73daad5e6946e...|    12936373|0x629A673A8242c2A...|44112634701076365...|0xA62E90BF944A7f5...|0xC69b4c6fFDBaF84...|                0|1627776481|\n|7de81ec5-bbf6-485...|0xe9c8dbd55c37189...|    12936373|0x1A92f7381B9F039...|                6554|0x1B64D74bB19C9d6...|0x114f1388fAB456c...|                0|1627776481|\n|e9ce8274-2ddd-4bf...|0xf6c06191e0af12d...|    12936373|0xb932a70A57673d8...|                4865|0x8c9F364bf7a56Ed...|0x900E7aD1ab18CeB...|                0|1627776481|\n|9cc5c9e4-e570-4b9...|0xefdb2cd352aee3f...|    12936373|0x06012c8cf97BEaD...|             1416156|0x7aB6478CDD77acd...|0xAF0b85097971e41...|                0|1627776481|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\nonly showing top 10 rows\n\n"}], "source": "df = sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"delimiter\", \",\").load(\"gs://nft_csvingestion/transfers.csv\")\ndf.show(10)"}, {"cell_type": "code", "execution_count": 3, "id": "98109737", "metadata": {"scrolled": true}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.transfers').partitionBy(\"nft_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 11, "id": "ce3bee3e", "metadata": {"collapsed": true}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40817)\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"}, {"ename": "Py4JNetworkError", "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:40817)", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:977\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n", "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1115\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n", "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)", "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark_transfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbigquery\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporaryGcsBucket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_bucket_temp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtendedSqlLiteDataset.transfers\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnft_address\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msave()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:243\u001b[0m, in \u001b[0;36mDataFrame.write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Interface for saving the content of the non-streaming :class:`DataFrame` out into external\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    storage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    :class:`DataFrameWriter`\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:885\u001b[0m, in \u001b[0;36mDataFrameWriter.__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msql_ctx\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1031\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1031\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:979\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeque\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:985\u001b[0m, in \u001b[0;36mGatewayClient._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    983\u001b[0m     connection \u001b[38;5;241m=\u001b[39m GatewayConnection(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property)\n\u001b[0;32m--> 985\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1127\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while trying to connect to the Java \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m   1126\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(msg)\n\u001b[0;32m-> 1127\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(msg, e)\n", "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:40817)"]}], "source": "spark_transfer.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.transfers').partitionBy(\"nft_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 6, "id": "99f58742", "metadata": {}, "outputs": [], "source": "conn = sqlite3.connect(db_path)"}, {"cell_type": "code", "execution_count": 7, "id": "3a6784e6", "metadata": {}, "outputs": [], "source": "cur = conn.execute(\"SELECT * from ownership_transitions\")\n\nrows = cur.fetchall()"}, {"cell_type": "code", "execution_count": 8, "id": "7d9df370", "metadata": {}, "outputs": [], "source": "table_columns = ['from_address', 'to_address', 'num_transitions']\n\nwith open(\"ownership_transitions.csv\", \"w\", newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(table_columns)\n    writer.writerows(rows)"}, {"cell_type": "code", "execution_count": 9, "id": "10ff7ca5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+---------------+\n|        from_address|          to_address|num_transitions|\n+--------------------+--------------------+---------------+\n|0x000000000000000...|0x000000000000000...|          83548|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|           5531|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|              1|\n|0x000000000000000...|0x000000000000000...|              4|\n|0x000000000000000...|0x000000000000000...|          19758|\n+--------------------+--------------------+---------------+\nonly showing top 10 rows\n\n"}], "source": "df = sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"delimiter\", \",\").load(\"gs://nft_csvingestion/ownership_transitions.csv\")\ndf.show(10)"}, {"cell_type": "code", "execution_count": 10, "id": "0feaf99a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.ownership_transitions').partitionBy(\"from_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 15, "id": "7618b956", "metadata": {}, "outputs": [], "source": "conn = sqlite3.connect(db_path)"}, {"cell_type": "code", "execution_count": 16, "id": "dca131bf", "metadata": {}, "outputs": [], "source": "cur = conn.execute(\"SELECT * from current_market_values\")\n\nrows = cur.fetchall()"}, {"cell_type": "code", "execution_count": 17, "id": "38c44ff9", "metadata": {}, "outputs": [], "source": "table_columns = ['nft_address', 'token_id', 'market_value']\n\nwith open(\"current_market_values.csv\", \"w\", newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(table_columns)\n    writer.writerows(rows)"}, {"cell_type": "code", "execution_count": 3, "id": "0c1064a9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------+------------------+\n|         nft_address|token_id|      market_value|\n+--------------------+--------+------------------+\n|0x00000000000b7F8...|       0| 30000000000000000|\n|0x00000000000b7F8...|       1|150000000000000000|\n|0x00000000000b7F8...|      10|150000000000000000|\n|0x00000000000b7F8...|      11| 30000000000000000|\n|0x00000000000b7F8...|      12| 90000000000000000|\n|0x00000000000b7F8...|      13| 90000000000000000|\n|0x00000000000b7F8...|      14| 90000000000000000|\n|0x00000000000b7F8...|      15| 30000000000000000|\n|0x00000000000b7F8...|      16|150000000000000000|\n|0x00000000000b7F8...|      17|150000000000000000|\n+--------------------+--------+------------------+\nonly showing top 10 rows\n\n"}], "source": "spark_current_market_values = sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"delimiter\", \",\").load(\"gs://nft_csvingestion/current_market_values.csv\")\nspark_current_market_values.show(10)"}, {"cell_type": "code", "execution_count": 4, "id": "04fc62b3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark_current_market_values.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.current_market_values').partitionBy(\"nft_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": 6, "id": "a7d94c0f", "metadata": {}, "outputs": [], "source": "conn = sqlite3.connect(db_path)\n\ncur = conn.execute(\"SELECT * from mints\")\n\nrows = cur.fetchall()"}, {"cell_type": "code", "execution_count": 7, "id": "47bc4e2a", "metadata": {}, "outputs": [], "source": "table_columns = ['event_id', 'transaction_hash', 'block_number', 'nft_address', 'token_id', 'from_address', 'to_address', 'transaction_value', 'timestamp']\n\nwith open(\"mints.csv\", \"w\", newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(table_columns)\n    writer.writerows(rows)"}, {"cell_type": "code", "execution_count": 2, "id": "05792b7e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|            event_id|    transaction_hash|block_number|         nft_address|            token_id|        from_address|          to_address|transaction_value| timestamp|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\n|6c6d226e-2096-4b5...|0xe47ac62111db3a6...|    12936415|0x02AA731631c6D7F...|                3223|0x000000000000000...|0x8D745Fb3311cC86...|                0|1627776933|\n|263c923f-4db9-4d8...|0xe47ac62111db3a6...|    12936415|0x02AA731631c6D7F...|                5077|0x000000000000000...|0x8D745Fb3311cC86...|                0|1627776933|\n|8baa8502-42f9-453...|0xe47ac62111db3a6...|    12936415|0x02AA731631c6D7F...|                5070|0x000000000000000...|0x8D745Fb3311cC86...|                0|1627776933|\n|364ee658-ff31-4d0...|0xe47ac62111db3a6...|    12936415|0x02AA731631c6D7F...|                3757|0x000000000000000...|0x8D745Fb3311cC86...|                0|1627776933|\n|58d3adc3-03d2-4e7...|0xd44be17c0298717...|    12936414|0x57f1887a8BF19b1...|32522027714413876...|0x000000000000000...|0x283Af0B28c62C09...| 2251725644794058|1627776925|\n|86a787d3-f60b-4a6...|0x2526fa548f4de7f...|    12936414|0xdf9Aa1012Fa49DC...|                1096|0x000000000000000...|0x2448681d0E9D101...|                0|1627776925|\n|05660bc3-f929-45b...|0xe29d9a2d602dfcc...|    12936413|0xdf9Aa1012Fa49DC...|                1094|0x000000000000000...|0x2448681d0E9D101...|                0|1627776923|\n|dfb04e18-c3de-45a...|0x7a54a15f048cd8d...|    12936412|0x02AA731631c6D7F...|                 161|0x000000000000000...|0xd397E4a615C7B4a...|                0|1627776905|\n|7d6c0cf9-4057-439...|0x27fbc5512ad6a6b...|    12936412|0x1808CB10ad0DC7b...|                4067|0x000000000000000...|0xDE16DF6abaD7F57...|30000000000000000|1627776905|\n|4d14cb62-48b5-4cb...|0xf584379502d2f5c...|    12936412|0xd0A07a76746707f...|                2122|0x000000000000000...|0x4555CBc05d168f2...|                0|1627776905|\n+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-----------------+----------+\nonly showing top 10 rows\n\n"}], "source": "spark_mints = sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"delimiter\", \",\").load(\"gs://nft_csvingestion/mints.csv\")\nspark_mints.show(10)"}, {"cell_type": "code", "execution_count": 3, "id": "ead4c3b9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark_mints.write.format('bigquery').option(\"temporaryGcsBucket\",\"temp_bucket_temp\").option('table', 'ExtendedSqlLiteDataset.mints').partitionBy(\"nft_address\").mode('overwrite').save()"}, {"cell_type": "code", "execution_count": null, "id": "4e213e0e", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 5}